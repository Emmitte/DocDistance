１　引　言实现人工智能是人类长期以来一直追求的梦想 = 0.0
虽然计算机技术在过去几十年里取得了长足的发展，但是实现真正意义上的机器智能至今仍然困难重重 = 0.0
伴随着神经解剖学的发展，观测大脑微观结构的技术手段日益丰富，人类对大脑组织的形态、结构与活动的认识越来越深入，人脑信息处理的奥秘也正在被逐步揭示 VS 以上为感知机学习 的原始形式，与之相对应的另一种结构是感知机学 习的对偶形式 = 0.08944271909999159
如何借助神经科学、脑科学与认知科学的研究成果，研究大脑信息表征、转换机理和学习规则，建立模拟大脑信息处理过程的智能计算模型，最终使机器掌握人类的认知规律，是“类脑智能”的研究目标 VS Ｈｅｂｂ学习规则和Ｄｅｌｔａ学习规则都是针对单 个神经元而提出的，在神经元组成的网络中参数的 学习规则将会在后续述及 = 0.16943474841747155
近年来，类脑智能已成为世界各国研究和角逐的热点 VS 以上先驱者所做的研究 工作为后来神经计算的出现铺平了道路，激发了许 多学者对这一领域的继续探索和研究 = 0.16666666666666666
继美国及欧盟各国之后，我国经过两三年筹备的“中国脑科学计划”在２０１５年浮出水面，科技部正在规划“脑科学与类脑研究”的重大专项，北京大学、清华大学、复旦大学等高校和中国科学院等研究机构也发力推动神经与类脑计算的相关研究，大规模“类脑智能”的研究正蓄势待发 VS 以上先驱者所做的研究 工作为后来神经计算的出现铺平了道路，激发了许 多学者对这一领域的继续探索和研究 = 0.1781741612749496
类脑智能是涉及计算科学、认知科学、神经科学与脑科学的交叉前沿方向 VS Ｍ－Ｐ模型是对 生物神经元信息处理模式的数学简化，后续的神经 网络研究工作都是以它为基础的 = 0.06900655593423542
类脑智能的实现离不开大脑神经系统的研究 VS 以上先驱者所做的研究 工作为后来神经计算的出现铺平了道路，激发了许 多学者对这一领域的继续探索和研究 = 0.1781741612749496
众所周知，人脑是由几十多亿个高度互联的神经元组成的复杂生物网络，也是人类分析、联想、记忆和逻辑推理等能力的来源 VS Ｍ－Ｐ模型是对 生物神经元信息处理模式的数学简化，后续的神经 网络研究工作都是以它为基础的 = 0.2004459314343183
神经元之间通过突触连接以相互传递信息，连接的方式和强度随着学习发生改变，从而将学习到的知识进行存储 VS 继Ｈｅｂｂ 学习规则之后，神经元的有监督Ｄｅｌｔａ学习规则被 提出，用以解决在输入输出已知的情况下神经元权 值的学习问题 = 0.3321819194149599
模拟人脑中信息存储和处理的基本单元－神经元而组成的人工神经网络模型具有自学习与自组织等智能行为，能够使机器具有一定程度上的智能水平 VS 神经元 ８期焦李成等：神经网络七十年：回顾与展望１６９９ 的输出ｙｉ 可以表示为如下形式： ｙｉ＝ｆ Σ ｎ ｊ＝１ ｗｉｊｘｊ－（ θｉ） （１） 　　该模型从逻辑功能器件的角度来描述神经元， 为神经网络的理论研究开辟了道路 = 0.18633899812498247
神经网络的计算结构和学习规则遵照生物神经网络设计，在数字计算机中，神经细胞接收周围细胞的刺激并产生相应输出信号的过程可以用“线性加权和”及“函数映射”的方式来模拟，而网络结构和权值调整的过程用优化学习算法实现 VS 继Ｈｅｂｂ 学习规则之后，神经元的有监督Ｄｅｌｔａ学习规则被 提出，用以解决在输入输出已知的情况下神经元权 值的学习问题 = 0.29735051672502627
按照该方式建立的这种仿生智能计算模型虽然不能和生物神经网络完全等价和媲美，但已经在某些方面取得了优越的性能 VS Ｍ－Ｐ模型是对 生物神经元信息处理模式的数学简化，后续的神经 网络研究工作都是以它为基础的 = 0.13801311186847084
从２０世纪４０年代的Ｍ－Ｐ神经元和Ｈｅｂｂ学习规则，到５０年代的Ｈｏｄｙｋｉｎ－Ｈｕｘｌｅｙ方程、感知器模型与自适应滤波器，再到６０年代的自组织映射网络、神经认知机、自适应共振网络，许多神经计算模型都发展成为信号处理、计算机视觉、自然语言处理与优化计算等领域的经典方法，为该领域带来了里程碑式的影响 VS Ｈｅｂｂ学习规则和Ｄｅｌｔａ学习规则都是针对单 个神经元而提出的，在神经元组成的网络中参数的 学习规则将会在后续述及 = 0.2735506022160966
目前神经网络已经发展了上百种模型，在诸如手写体识别［１－２］、图像标注［３］、语义理解［４－６］和语音识别［７－９］等技术领域取得了非常成功的应用 VS 神经元 ８期焦李成等：神经网络七十年：回顾与展望１６９９ 的输出ｙｉ 可以表示为如下形式： ｙｉ＝ｆ Σ ｎ ｊ＝１ ｗｉｊｘｊ－（ θｉ） （１） 　　该模型从逻辑功能器件的角度来描述神经元， 为神经网络的理论研究开辟了道路 = 0.11180339887498948
从数据容量和处理速度来看，目前大多数神经网络是生物网络的简化形式，在应对海量数据和处理复杂任务时显得力不从心 VS Ｍ－Ｐ模型是对 生物神经元信息处理模式的数学简化，后续的神经 网络研究工作都是以它为基础的 = 0.2004459314343183
例如，人脑被证明可以在没有导师监督的情况下主动地完成学习任务，仅凭借传统的浅层神经网络是无法实现这一点的 VS 继Ｈｅｂｂ 学习规则之后，神经元的有监督Ｄｅｌｔａ学习规则被 提出，用以解决在输入输出已知的情况下神经元权 值的学习问题 = 0.2680281337094487
最近发展起来的深层神经网络就是一种类脑智能软件系统，它使得人工智能的研究进入了一个新阶段 VS １９５８年，Ｒｏｓｅｎｂｌａｔｔ等人成功研制出了代号为 Ｍａｒｋ　Ｉ的感知机（Ｐｅｒｃｅｐｔｒｏｎ），这是历史上首个将 神经网络的学习功能用于模式识别的装置，标志着 神经网路进入了新的发展阶段［２２］ = 0.15191090506255
深层神经网络通过增加网络的层数来模拟人脑复杂的层次化认知规律，以使机器获得“抽象概念”的能力，在无监督特征学习方面具有更强的能力 VS 继Ｈｅｂｂ 学习规则之后，神经元的有监督Ｄｅｌｔａ学习规则被 提出，用以解决在输入输出已知的情况下神经元权 值的学习问题 = 0.15488061853247329
然而，受到计算平台和学习算法的限制，对深层神经网络的研究曾一度消弭 VS 继Ｈｅｂｂ 学习规则之后，神经元的有监督Ｄｅｌｔａ学习规则被 提出，用以解决在输入输出已知的情况下神经元权 值的学习问题 = 0.1856953381770519
２００６年，Ｈｉｎｔｏｎ在《科学》上提出了一种面向复杂通用学习任务的深层神经网络，指出具有大量隐层的网络具有优异的特征学习能力，而网络的训练可以采用“逐层初始化”与“反向微调”技术解决 VS Ｈｅｂｂ学习规则和Ｄｅｌｔａ学习规则都是针对单 个神经元而提出的，在神经元组成的网络中参数的 学习规则将会在后续述及 = 0.23539595453459985
人类借助神经网络找到了处理“抽象概念”的方法，神经网络的研究又进入了一个崭新的时代［１０－１２］，深度学习的概念开始被提出 VS 继Ｈｅｂｂ 学习规则之后，神经元的有监督Ｄｅｌｔａ学习规则被 提出，用以解决在输入输出已知的情况下神经元权 值的学习问题 = 0.16609095970747995
深度学习兴起的背景是计算能力的提高与大数据时代的来临，其核心理念是通过增加网络的层数来让机器自动地从数据中进行学习 VS Ｈｅｂｂ学习规则和Ｄｅｌｔａ学习规则都是针对单 个神经元而提出的，在神经元组成的网络中参数的 学习规则将会在后续述及 = 0.2842676218074806
深层神经网络能够获得巨大成功与其对应在训练算法上所取得的突破性进展是密不可分的 VS 神经元 ８期焦李成等：神经网络七十年：回顾与展望１６９９ 的输出ｙｉ 可以表示为如下形式： ｙｉ＝ｆ Σ ｎ ｊ＝１ ｗｉｊｘｊ－（ θｉ） （１） 　　该模型从逻辑功能器件的角度来描述神经元， 为神经网络的理论研究开辟了道路 = 0.1111111111111111
传统的反向传播算法（Ｂａｃｋ　Ｐｒｏｐａｇａｔｉｏｎ）随着传递层数的增加，残差会越来越小，出现所谓的“梯度扩散”（Ｇｒａｄｉｅｎｔ　Ｄｉｆｆｕｓｉｏｎ）现象，故而不适于深层网络的训练 VS Ｍ－Ｐ模型是对 生物神经元信息处理模式的数学简化，后续的神经 网络研究工作都是以它为基础的 = 0.058321184351980436
深度学习模型中的受限玻尔兹曼机（Ｒｅｓｔｒｉｃｔｅｄ　Ｂｏｌｔｚｍａｎｎ　Ｍａｃｈｉｎｅｓ）和自编码器（Ａｕｔｏ－Ｅｎｃｏｄｅｒ）采用了“自下而上的无监督学习”和“自顶向下的监督学习”策略来实现对网络的“预训练”和“微调”，可使学习算法收敛到较为理想的解上，而当前使用更为广泛的卷积神经网络（Ｃｏｎｖｏｌｕｔｉｏｎａｌ　Ｎｅｕｒａｌ　Ｎｅｔｗｏｒｋｓ）则采用局部感受野、权值共享和时空亚采样的思想，显著地减少了网络中自由参数的个数，并且使得采用反向传播来进行网络的并行学习成为可能 VS Ｈｅｂｂ学习规则和Ｄｅｌｔａ学习规则都是针对单 个神经元而提出的，在神经元组成的网络中参数的 学习规则将会在后续述及 = 0.3750598038437739
除了以上优势外，深度学习最具吸引力的地方还在于能凭借无标签的数据来进行学习，而不需要依赖于监督信息的支撑［１３］ VS 继Ｈｅｂｂ 学习规则之后，神经元的有监督Ｄｅｌｔａ学习规则被 提出，用以解决在输入输出已知的情况下神经元权 值的学习问题 = 0.306381676672686
现实世界的很多问题中，对数据的标记通常是耗时耗力甚至是不可行的，无监督学习可以自动抽取出抽象的高层属性和特征，是解决样本标记难问题的一个重大突破 VS 继Ｈｅｂｂ 学习规则之后，神经元的有监督Ｄｅｌｔａ学习规则被 提出，用以解决在输入输出已知的情况下神经元权 值的学习问题 = 0.18208926018230745
深度学习的成功引起了包括产业界和学术界在内的诸多人士的关注，其影响力甚至上升到了国家战略层面 VS 继Ｈｅｂｂ 学习规则之后，神经元的有监督Ｄｅｌｔａ学习规则被 提出，用以解决在输入输出已知的情况下神经元权 值的学习问题 = 0.1351132047333135
２０１２年６月，《纽约时报》披露了Ｇｏｏｇｌｅ　Ｂｒａｉｎ项目，该项目拟计划在包含１６　０００个中央处理单元的分布式并行计算平台上构建一种被称之为“深度神经网络”的类脑学习模型，其主要负责人为机器学习界的泰斗、来自斯坦福大学的Ｎｇ教授和Ｇｏｏｇｌｅ软件架构天才、大型并发编程框架Ｍａｐ　Ｒｅｄｕｃｅ的作者Ｊｅｆｆ　Ｄｅａｎ；２０１２年１０月，在天津举行的“２１世纪的计算大会”上，微软首席研究官Ｒｉｃｋ　Ｒａｓｈｉｄ展示了一套全自动同声传译系统，演讲者的英文能够被实时、流畅地转换成与之对应的、音色相近的中文，其背后的关键技术深度神经网络也逐渐被人们所知 VS 继Ｈｅｂｂ 学习规则之后，神经元的有监督Ｄｅｌｔａ学习规则被 提出，用以解决在输入输出已知的情况下神经元权 值的学习问题 = 0.11371470653683552
２０１３年１月，作为百度公司创始人兼ＣＥＯ的李彦宏在其年会上宣布了成立百度研究院的计划，并且强调首当其冲的就是组建“深度学习研究所” VS 继Ｈｅｂｂ 学习规则之后，神经元的有监督Ｄｅｌｔａ学习规则被 提出，用以解决在输入输出已知的情况下神经元权 值的学习问题 = 0.11371470653683552
在２０１５年３月９日的两会期间，李彦宏又提议设立“中国大脑”计划的提案，与２０１３年１月和２０１３年４月的“欧盟大脑计划”和“美国大脑计划”相呼应 VS 以上为感知机学习 的原始形式，与之相对应的另一种结构是感知机学 习的对偶形式 = 0.03535533905932737
２０１５年３月，阿里巴巴公司的创始人马云通过支付宝的“刷脸支付”功能，在德国举行的ＩＴ 博览会上成功购得了一款汉诺威纪念邮票 VS １９５８年，Ｒｏｓｅｎｂｌａｔｔ等人成功研制出了代号为 Ｍａｒｋ　Ｉ的感知机（Ｐｅｒｃｅｐｔｒｏｎ），这是历史上首个将 神经网络的学习功能用于模式识别的装置，标志着 神经网路进入了新的发展阶段［２２］ = 0.07968190728895957
这一人脸识别技术在商业领域的应用雏形所采用的是基于神经网络的技术，其网络训练所使用的正是“深度学习算法” VS Ｈｅｂｂ学习规则和Ｄｅｌｔａ学习规则都是针对单 个神经元而提出的，在神经元组成的网络中参数的 学习规则将会在后续述及 = 0.16888013236829963
在学术界，以Ｈｉｎｔｏｎ、ＬｅＣｕｎ、Ｂｅｎｇｉｏ和Ｎｇ等为代表的神经网络大师们不断将深度学习的研究推向新的高峰，对包括计算机视觉、自然语言处理和机器学习在内的诸多领域带来了深远的影响［１４］ VS 继Ｈｅｂｂ 学习规则之后，神经元的有监督Ｄｅｌｔａ学习规则被 提出，用以解决在输入输出已知的情况下神经元权 值的学习问题 = 0.20689655172413796
自２００６年深度学习出现以来，关于深度学习理论和应用方面的研究文献在国际知名期刊和会议上不断涌现，如《自然》、《科学》、ＰＡＭＩ、ＮＩＰＳ、ＣＶＰＲ、ＩＣＭＬ等 VS 继Ｈｅｂｂ 学习规则之后，神经元的有监督Ｄｅｌｔａ学习规则被 提出，用以解决在输入输出已知的情况下神经元权 值的学习问题 = 0.12456821978060995
同时，由Ｂｅｎｇｉｏ等人编写的第一本关于深度学习的专著“Ｄｅｅｐ　Ｌｅａｒｎｉｎｇ”也即将由ＭＩＴ出版社出版 VS 继Ｈｅｂｂ 学习规则之后，神经元的有监督Ｄｅｌｔａ学习规则被 提出，用以解决在输入输出已知的情况下神经元权 值的学习问题 = 0.15450786078738143
包括斯坦福大学、卡内基梅隆大学、纽约大学、多伦多大学等在内的机构都提供了深度学习的公开课程，并公开了实验数据和源代码，为深度学习的进一步发展做出了贡献 VS 继Ｈｅｂｂ 学习规则之后，神经元的有监督Ｄｅｌｔａ学习规则被 提出，用以解决在输入输出已知的情况下神经元权 值的学习问题 = 0.17841031003501578
在国内，深度学习也受到了学术界的广泛关注，但目前主要是以深度学习的应用研究为主，在理论方面的工作相对较少 VS 继Ｈｅｂｂ 学习规则之后，神经元的有监督Ｄｅｌｔａ学习规则被 提出，用以解决在输入输出已知的情况下神经元权 值的学习问题 = 0.2785430072655778
以北京大学、浙江大学、上海交通大学、哈尔滨工业大学和西安电子科技大学等为代表的研究人员将深度学习算法应用到遥感图像分类［１５］、多媒体检索［１６］、交通流预测［１７］和盲图像质量评价［１８］等领域，取得了较传统方法更优的效果 VS 感知机是二分类 的线性判别模型，旨在通过最小化误分类损失函数 来优化分类超平面，从而对新的实例实现准确预测 = 0.12326671027227314
本文将以神经网络的理论和应用为主线，回顾神经网络在过去七十多年的发展历程及主要成就，重点对新近发展起来的深度学习进行阐述和讨论，并对未来的研究方向做出展望 VS 神经元 ８期焦李成等：神经网络七十年：回顾与展望１６９９ 的输出ｙｉ 可以表示为如下形式： ｙｉ＝ｆ Σ ｎ ｊ＝１ ｗｉｊｘｊ－（ θｉ） （１） 　　该模型从逻辑功能器件的角度来描述神经元， 为神经网络的理论研究开辟了道路 = 0.19611613513818404
Avg similar = 0.17022026297514925
